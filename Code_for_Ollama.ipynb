{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867799e6",
   "metadata": {},
   "source": [
    "This notebook is a introduction guide on how to use Ollama's on your local machine to perform task such as summarizing web content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c5bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                                       #make http requests for pirticular URL\n",
    "from bs4 import BeautifulSoup                         #web scraping \n",
    "from IPython.display import Markdown, display         #display and render markdown content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f29d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants, making some variables to use them in further code\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25fe781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the task or command you want to perform: poem on rain\n",
      "[{'role': 'user', 'content': 'poem on rain'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a hard coded messages list (it is commented out right now)\n",
    "'''\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Summarize youtube.com\"}\n",
    "]\n",
    "'''\n",
    "\n",
    "#OR use below code for real time input \n",
    "\n",
    "# Function to get user input and create messages list\n",
    "def get_user_input():\n",
    "    user_input = input(\"Enter the task or command you want to perform: \")\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "# Example usage\n",
    "messages = get_user_input()\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4568b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to define payload in Jason format\n",
    "\n",
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce389610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded (remove the # if you wish to run this part and change the model accordingly)\n",
    "\n",
    "#!ollama pull llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b3c2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a poem about rain:\n",
      "\n",
      "**Rainy Day Blues**\n",
      "\n",
      "The sky is gray, the clouds are low\n",
      "A soothing melody, the droplets flow\n",
      "Gentle fingers tapping on my roof above\n",
      "A calming lullaby, a symphony of love\n",
      "\n",
      "The scent of wet earth rises high and sweet\n",
      "As petals lift to greet the rain's soft beat\n",
      "Droplets cling to leaves, like diamonds bright\n",
      "Reflecting sunbeams, in shimmering light\n",
      "\n",
      "Rainy days are made for dreaming deep\n",
      "For letting go, and watching worries creep\n",
      "Away with every drop, as puddles grow\n",
      "And life's troubles dwindle, like autumn's snow\n",
      "\n",
      "In rain-soaked streets, reflections stare back\n",
      "At me, at you, at all the love that's lacking\n",
      "A chance to reconnect, to mend the tear\n",
      "To let the healing balm of rain wash away fear\n",
      "\n",
      "So let the rain come down, and pour from above\n",
      "Bringing life to parched earth, and a heart full of love.\n"
     ]
    }
   ],
   "source": [
    "#Now final part, making a POST request from local machine to local machine on address of Ollama i.e. http://localhost:11434/api/chat\n",
    "#Ollama is running on http://localhost:11434\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f877c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecb0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ff0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef031b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cd98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b104c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc033e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
