# ü¶• Ollama Notebook - Local LLM Deployment

## üöÄ Overview

This repository contains a Jupyter Notebook demonstrating how to set up and run **Llama 3.1** using **Ollama**, enabling local inference without relying on cloud-based LLMs like OpenAI or Google.

## ‚úÖ Prerequisites

Before running the notebook, ensure you have the following installed on your system:

1Ô∏è‚É£ **Python 3.8+** ‚Äì [Download here](https://www.python.org/downloads/)\
2Ô∏è‚É£ **Ollama** ‚Äì Install from [Ollama's official site](https://ollama.com/)\
3Ô∏è‚É£ **Jupyter Notebook** ‚Äì Install using:

```bash
pip install notebook
```

4Ô∏è‚É£ **Required Python Libraries** (Install using `pip`):

```bash
pip install torch transformers sentencepiece
```

## ‚öôÔ∏è Installation & Setup

Follow these steps to set up your environment:

1. **Clone the repository**

   ```bash
   git clone https://github.com/KapilGaur9292/LLM.git  
   cd LLM
   ```

2. **Launch Jupyter Notebook**

   ```bash
   jupyter notebook
   ```

3. **Run the notebook**

   - Open `Code_for_Ollama.ipynb`
   - Follow the steps inside to load and interact with Llama 3.1 locally

## ü§ñ Features

- Run Llama 3.1 locally with **no API calls**
- Supports **chat-based interactions**
- Easily adaptable for **custom fine-tuning**

## ‚≠ê Star the Repo & Stay Tuned

I'll be adding more notebooks, covering topics from **basic to advanced** ML & GenAI! üöÄ

\#LocalLLM #Ollama #Llama3 #GenerativeAI #MachineLearning #Python #GitHub

